{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\smart\\Documents\\Computer Vision\\OCRecognition\\myData\"\n",
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "dimension = (32,32, 3)\n",
    "filter1 = (5,5)\n",
    "filter2 = (3,3)\n",
    "noOfFilter = 128\n",
    "noOfNodes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number Of Class Detected :  10\n",
      "Importing Images ... ... ... \n",
      "0 1 2 3 4 5 6 7 8 9  \n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "classes = []\n",
    "\n",
    "myList = os.listdir(path)\n",
    "noOfClasses = len(myList)\n",
    "print(\"Total Number Of Class Detected : \", len(myList))\n",
    "\n",
    "print('Importing Images ... ... ... ')\n",
    "for x in range (0, noOfClasses):\n",
    "    myPicList = os.listdir(path + '/' + str(x))\n",
    "    for y in myPicList:\n",
    "        curImg = cv2.imread(path + '/' + str(x) + '/' + y)\n",
    "        curImg = cv2.resize(curImg, (32,32))\n",
    "        images.append(curImg)\n",
    "        classes.append(x)\n",
    "    print(x, end = ' ')\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "classes = np.array(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, classes, test_size = test_size)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size = val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[657, 628, 660, 630, 669, 670, 640, 644, 657, 647]\n"
     ]
    }
   ],
   "source": [
    "noOfSamples = []\n",
    "\n",
    "for x in range (0, noOfClasses):\n",
    "    noOfSamples.append(len(np.where(y_train==x)[0]))\n",
    "print(noOfSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.bar(range(0, noOfClasses), noOfSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = img/255\n",
    "    return  img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"img = preProcessing(X_train[10])\\nimg = cv2.resize(img, (dimension))\\ncv2.imshow('img',img)\\ncv2.waitKey(0)\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''img = preProcessing(X_train[10])\n",
    "img = cv2.resize(img, (dimension))\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(list(map(preProcessing, X_train)))\n",
    "X_test = np.array(list(map(preProcessing, X_test)))\n",
    "X_validation = np.array(list(map(preProcessing, X_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6502, 32, 32)\n",
      "(2032, 32, 32)\n",
      "(1626, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], X_validation.shape[1], X_validation.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, noOfClasses)\n",
    "y_test = to_categorical(y_test, noOfClasses)\n",
    "y_validation = to_categorical(y_validation, noOfClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(noOfFilter, filter1, input_shape = (dimension[0], dimension[1], 1), activation = 'relu'))\n",
    "model.add(Conv2D(noOfFilter, filter1, activation = 'relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(noOfFilter//2, filter2, activation = 'relu'))\n",
    "model.add(Conv2D(noOfFilter//2, filter2, activation = 'relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(noOfNodes, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(noOfClasses, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(lr = 0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 128)       3328      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 24, 24, 128)       409728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 10, 10, 64)        73792     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               512500    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 1,041,286\n",
      "Trainable params: 1,041,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'fit_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-9b79c64c04ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model = model.fit_generator(datagen.flow(X_train, y_train, batch_size = 50), steps_per_epoch = 2000, \n\u001b[0m\u001b[0;32m      2\u001b[0m                             epochs = 10, validation_data = (X_validation, y_validation), shuffle = True)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'History' object has no attribute 'fit_generator'"
     ]
    }
   ],
   "source": [
    "model = model.fit_generator(datagen.flow(X_train, y_train, batch_size = 50), steps_per_epoch = 2000, \n",
    "                            epochs = 10, validation_data = (X_validation, y_validation), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
